{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Sentence\n",
    "西村康稔官房副長官は4日の記者会見で、消費税率を10月に10％に引き上げた後、さらに10％超へと引き上げることは「（政府としては）現在検討していない」と述べた。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 871891/871891 [00:01<00:00, 647039.14B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '西', '村', '康', '稔', '官', '房', '副', '長', '官', 'は4', '日', 'の', '記', '者', '[MASK]', '見', 'て', '、', '消', '費', '税', '率', 'を', '##10', '月', 'に1', '##0', '％', 'に', '引', 'き', '上', 'けた', '後', '、', 'さらに', '##10', '％', '超', 'へと', '引', 'き', '上', 'ける', '##ことは', '「', '（', '政', '府', 'としては', '）', '現', '在', '検', '討', 'していない', '」', 'と', '述', 'へた', '。', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
    "\n",
    "text = \"[CLS] 西村康稔官房副長官は4日の記者[MASK]見で、消費税率を10月に10％に引き上げた後、さらに10％超へと引き上げることは「（政府としては）現在検討していない」と述べた。 [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 7748, 4484, 3536, 6288, 3197, 3927, 2217, 9026, 3197, 85002, 4316, 1537, 7798, 6885, 103, 7753, 1531, 1482, 5102, 8109, 6287, 5674, 1562, 20216, 4448, 56762, 10995, 10026, 1534, 3589, 1518, 1657, 17052, 3651, 1482, 26385, 20216, 10026, 8224, 33960, 3589, 1518, 1657, 19499, 34885, 1492, 10028, 4250, 3525, 27167, 10029, 5721, 2770, 4678, 7793, 63397, 1493, 1532, 8445, 85688, 1483, 102]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "segments_ids = [0] * len(tokenized_text)\n",
    "\n",
    "print(indexed_tokens)\n",
    "print(segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 623743758/623743758 [22:42<00:00, 457898.50B/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "を\n"
     ]
    }
   ],
   "source": [
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-multilingual-uncased')\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(tokens_tensor, segments_tensors)\n",
    "    \n",
    "masked_index = tokenized_text.index(\"[MASK]\")\n",
    "predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "\n",
    "print(predicted_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
